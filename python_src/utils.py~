# utils.py
import numpy as np
import scipy.io as sio
import mat73

def load_mat(filename):
    """
    Robustly loads .mat files (both v7 and v7.3).
    Returns a dictionary where structs are converted to nested dicts.
    """
    try:
        # Try standard scipy loader (v7 and below)
        data = sio.loadmat(filename, squeeze_me=True, struct_as_record=False)
    except NotImplementedError:
        # Fallback for v7.3 files
        data = mat73.loadmat(filename)
    
    # Helper to recursively convert scipy mat_structs to dicts
    def _check_keys(d):
        if isinstance(d, sio.matlab.mat_struct):
            d = {k: _check_keys(getattr(d, k)) for k in d._fieldnames}
        elif isinstance(d, dict):
            d = {k: _check_keys(v) for k, v in d.items()}
        return d

    return _check_keys(data)

def regularize_covariance(sigma, max_cond=500):
    """
    Applies Tikhonov regularization to ensure condition number <= max_cond.
    """
    # Eigendecomposition (hermitian=True for symmetric/complex-hermitian matrices)
    vals, vecs = np.linalg.eigh(sigma)
    
    min_eig = np.min(vals)
    max_eig = np.max(vals)
    
    # Avoid divide by zero if matrix is all zeros
    if min_eig <= 0:
        min_eig = 1e-10
        
    current_cond = max_eig / min_eig
    
    if current_cond > max_cond:
        # Analytical solution for lambda
        lambda_val = (max_eig - max_cond * min_eig) / (max_cond - 1)
        sigma_reg = sigma + lambda_val * np.eye(sigma.shape[0])
    else:
        sigma_reg = sigma
        
    return sigma_reg

def estimate_noise_covariance(data, frame_size=10):
    """
    Estimates noise covariance from background.
    data: (nx, ny, nt) complex array
    frame_size: int or tuple (x, y)
    """
    nx, ny, nt = data.shape
    
    if isinstance(frame_size, int):
        fs_x, fs_y = frame_size, frame_size
    else:
        fs_x, fs_y = frame_size
        
    # Python reshape order='F' matches MATLAB's column-major ordering
    data_reshaped = data.reshape(-1, nt, order='F')
    
    # Create background mask
    mask = np.ones((nx, ny), dtype=bool)
    mask[fs_x : nx - fs_x, fs_y : ny - fs_y] = False
    
    bg_voxels = data[mask].reshape(-1, nt, order='F')
    
    # Calculate Covariance (rowvar=False means rows are observations, cols are variables)
    # However, numpy cov expects variables as rows by default (rowvar=True).
    # Our data is [N_samples, N_timepoints]. We want N_t x N_t cov.
    sigma = np.cov(bg_voxels, rowvar=False)
    
    return regularize_covariance(sigma, 500)

def crop_image(img, target_shape):
    """Central crop helper if needed."""
    cx, cy = img.shape[0] // 2, img.shape[1] // 2
    tx, ty = target_shape[0] // 2, target_shape[1] // 2
    return img[cx-tx:cx+tx, cy-ty:cy+ty]
