# solvers.py
import numpy as np
from scipy.stats import chi2

def get_b1_limits(options, dict_b1, n_voxels):
    """Helper to determine B1 search range per voxel."""
    b1_mode = options.get('b1_mode', 'none').lower()
    
    if b1_mode == 'none':
        return np.tile([np.min(dict_b1), np.max(dict_b1)], (n_voxels, 1))
    
    elif b1_mode == 'map':
        b1_in = options['b1_input'].flatten(order='F')
        # Find nearest neighbor
        idx = np.abs(dict_b1[None, :] - b1_in[:, None]).argmin(axis=1)
        val = dict_b1[idx]
        return np.column_stack((val, val))
        
    elif b1_mode == 'range':
        # Expecting Nx, Ny, 2 input
        b1_in = options['b1_input'].reshape(-1, 2, order='F')
        idx_min = np.abs(dict_b1[None, :] - b1_in[:, 0][:, None]).argmin(axis=1)
        idx_max = np.abs(dict_b1[None, :] - b1_in[:, 1][:, None]).argmin(axis=1)
        return np.column_stack((dict_b1[idx_min], dict_b1[idx_max]))

def fit_mri_params_lrt(data, sigma, D, options=None):
    if options is None: options = {}
    alpha = options.get('alpha', 0.05)
    
    # Unpack Dictionary
    # Ensure standard dictionary access whether struct or dict
    D_mag = D['magnetization'] if isinstance(D, dict) else D.magnetization
    D_lut = D['lookup_table'] if isinstance(D, dict) else D.lookup_table
    
    nx, ny, nt = data.shape
    n_voxels = nx * ny
    Xobs = data.reshape(n_voxels, nt, order='F').T  # [Nt, N_voxels]

    # Process B1 Limits
    dict_b1 = np.unique(D_lut[:, 0])
    b1_limits = get_b1_limits(options, dict_b1, n_voxels)
    
    # Prepare Outputs
    res = {
        'q': np.full(n_voxels, np.nan),
        'q_ci': np.full((n_voxels, 2), np.nan),
    }

    # Chi-Squared Thresholds
    is_fixed = (b1_limits[:, 0] == b1_limits[:, 1])
    dof = np.full(n_voxels, 2)
    dof[is_fixed] = 1
    chi2_vals = chi2.ppf(1 - alpha, dof)

    # Unique B1 ranges processing
    unique_ranges = np.unique(b1_limits, axis=0)
    
    for r_min, r_max in unique_ranges:
        v_idx = np.where((b1_limits[:, 0] == r_min) & (b1_limits[:, 1] == r_max))[0]
        if len(v_idx) == 0: continue
        
        # Slice Dictionary
        mask = (D_lut[:, 0] >= r_min) & (D_lut[:, 0] <= r_max)
        D_sub = D_mag[:, mask]
        lut_sub = D_lut[mask, :]
        
        # Initial Estimate (Cosine Sim)
        X_sub = Xobs[:, v_idx]
        X_norm = X_sub / np.linalg.norm(X_sub, axis=0, keepdims=True)
        ip = np.abs(X_norm.conj().T @ D_sub) # [N_vox_sub, N_atoms]
        best_atom = np.argmax(ip, axis=1)
        
        # Save Point Estimates
        res['q'][v_idx] = lut_sub[best_atom, 1]
        
        # Solver Core (Assume full length for simulation simplicity or implement truncation logic)
        # Note: For full simulation parity, I am assuming no truncation for now 
        # unless specifically passed in options.
        
        # Precompute terms
        # Sigma is [Nt, Nt], D_sub is [Nt, N_atoms], X_sub is [Nt, N_vox]
        # Use solve for stability: Sigma \ D -> solve(Sigma, D)
        S_inv_D = np.linalg.solve(sigma, D_sub)
        S_inv_X = np.linalg.solve(sigma, X_sub)
        
        A = np.real(np.sum(X_sub.conj() * S_inv_X, axis=0))    # [N_vox]
        B = D_sub.conj().T @ S_inv_X                           # [N_atoms, N_vox]
        C = np.real(np.sum(D_sub.conj() * S_inv_D, axis=0))    # [N_atoms]
        
        # Profile Likelihood
        term2 = (np.abs(B)**2) / C[:, None] # Broadcast C across voxels
        resid = A[None, :] - term2          # [N_atoms, N_vox]
        
        resid[resid <= 0] = np.finfo(float).eps
        nll = nt * np.log(resid)
        
        min_nll = np.min(nll, axis=0)
        lrt_stat = 2 * (nll - min_nll)
        lrt_stat[lrt_stat < 0] = 0
        
        # Threshold
        thresh = chi2_vals[v_idx]
        valid_mask = lrt_stat <= thresh[None, :] # [N_atoms, N_vox]
        
        # Calculate CI
        q_grid = lut_sub[:, 1]
        
        # Vectorized Min/Max find
        # We iterate voxels here or use masked arrays. Iteration is safe for reasonable N.
        # Faster approach:
        q_tiled = np.tile(q_grid[:, None], (1, len(v_idx)))
        q_tiled[~valid_mask] = np.nan
        
        res['q_ci'][v_idx, 0] = np.nanmin(q_tiled, axis=0)
        res['q_ci'][v_idx, 1] = np.nanmax(q_tiled, axis=0)

    return {}, res # Return generic structs to match MATLAB unpacking

def fit_mri_params_bayesian(data, sigma, D, options=None):
    if options is None: options = {}
    alpha = options.get('alpha', 0.05)
    
    D_mag = D['magnetization'] if isinstance(D, dict) else D.magnetization
    D_lut = D['lookup_table'] if isinstance(D, dict) else D.lookup_table
    
    nx, ny, nt = data.shape
    n_voxels = nx * ny
    Xobs = data.reshape(n_voxels, nt, order='F').T 

    dict_b1 = np.unique(D_lut[:, 0])
    b1_limits = get_b1_limits(options, dict_b1, n_voxels)
    
    res = {
        'q': np.full(n_voxels, np.nan),
        'q_ci': np.full((n_voxels, 2), np.nan),
    }
    
    unique_ranges = np.unique(b1_limits, axis=0)
    
    for r_min, r_max in unique_ranges:
        v_idx = np.where((b1_limits[:, 0] == r_min) & (b1_limits[:, 1] == r_max))[0]
        if len(v_idx) == 0: continue

        # Filter Dictionary
        mask = (D_lut[:, 0] >= r_min) & (D_lut[:, 0] <= r_max)
        lut_sub = D_lut[mask, :]
        D_sub = D_mag[:, mask]
        
        # Sort (Python unique returns sorted, but let's ensure grid structure)
        # Lexsort sorts by last key first, so passed (q, b1) sorts by b1 then q
        sort_idx = np.lexsort((lut_sub[:, 1], lut_sub[:, 0])) 
        lut_sub = lut_sub[sort_idx]
        D_sub = D_sub[:, sort_idx]
        
        sub_b1_grid = np.unique(lut_sub[:, 0])
        sub_q_grid = np.unique(lut_sub[:, 1])
        
        # Solver
        X_sub = Xobs[:, v_idx]
        
        # Posterior Calculation
        S_inv_D = np.linalg.solve(sigma, D_sub)
        S_inv_X = np.linalg.solve(sigma, X_sub)
        
        A = np.real(np.sum(X_sub.conj() * S_inv_X, axis=0))
        B = D_sub.conj().T @ S_inv_X 
        C = np.real(np.sum(D_sub.conj() * S_inv_D, axis=0))
        
        term = (np.abs(B)**2) / C[:, None]
        RSS = A[None, :] - term
        RSS[RSS <= 0] = np.finfo(float).eps
        
        log_prob = (1 - nt) * np.log(RSS) - np.log(C[:, None])
        
        # Grid Reshape [nq, nb1, nvox]
        nq, nb1 = len(sub_q_grid), len(sub_b1_grid)
        log_prob_grid = log_prob.reshape(nq, nb1, len(v_idx), order='F') # MATLAB-like reshape
        
        # Normalize (Log-Sum-Exp)
        max_lp = np.max(log_prob.reshape(-1, len(v_idx)), axis=0)
        prob_grid = np.exp(log_prob_grid - max_lp[None, None, :])
        
        # Marginalize B1
        if nb1 > 1:
            p_q_raw = np.trapz(prob_grid, sub_b1_grid, axis=1)
        else:
            p_q_raw = prob_grid[:, 0, :]
            
        # Normalize p(q)
        norm_q = np.trapz(p_q_raw, sub_q_grid, axis=0)
        p_q = p_q_raw / norm_q[None, :]
        
        # Greedy CI
        # (Simplified vectorized greedy or per-voxel loop)
        for i, vid in enumerate(v_idx):
            # Point estimate (Mean)
            mean_val = np.trapz(sub_q_grid * p_q[:, i], sub_q_grid)
            res['q'][vid] = mean_val
            
            # CI
            lb, ub = calc_ci_greedy(sub_q_grid, p_q[:, i], mean_val, 1-alpha)
            res['q_ci'][vid, :] = [lb, ub]
            
    return {}, res

def calc_ci_greedy(grid, prob, center, conf):
    # Find nearest index to center
    idx = (np.abs(grid - center)).argmin()
    L, R = idx, idx
    acc_prob = 0.0
    n = len(grid)
    
    while acc_prob < conf and (L > 0 or R < n-1):
        # Potential Mass Left
        mass_L = -1
        if L > 0:
            mass_L = np.trapz(prob[L-1:R+1], grid[L-1:R+1])
            
        # Potential Mass Right
        mass_R = -1
        if R < n-1:
            mass_R = np.trapz(prob[L:R+2], grid[L:R+2])
            
        if mass_L > mass_R:
            L -= 1; acc_prob = mass_L
        else:
            R += 1; acc_prob = mass_R
            
    return grid[L], grid[R]
